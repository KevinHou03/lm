'''
1.ä»€ä¹ˆå«åšé—¨æ§ï¼š
    ä¸æ˜¯æ¯ä¸ªè§‚å¯Ÿå€¼éƒ½æ˜¯åŒç­‰é‡è¦ï¼Œå¥å­ä¸­ä¹Ÿæ˜¯ï¼Œå…³é”®è¯æ¯”è¾ƒé‡è¦
    æƒ³è¦è®°ä½ç›¸å…³çš„è§‚å¯Ÿï¼Œé‚£ä¹ˆéœ€è¦èƒ½å…³æ³¨çš„æœºåˆ¶ï¼šï¼ˆæ›´æ–°é—¨ï¼‰ä»¥åŠèƒ½é—å¿˜çš„æœºåˆ¶ï¼ˆé‡ç½®é—¨ï¼‰
    å¯¹äºæ™®é€šRNNæ¥è¯´ï¼Œæ‰€æœ‰ä¸œè¥¿éƒ½ä¸€æ ·é‡è¦ï¼Œä½†æ˜¯GRUé—¨æ§å¾ªç¯ç½‘ç»œï¼Œå°±å¯ä»¥å…³æ³¨åˆ°å“ªä¸ªæ›´é‡è¦ï¼Œå“ªä¸ªæ›´ä¸é‡è¦

2. ä»€ä¹ˆå« é—¨ï¼Ÿ
    RNNä¸­çš„è¾“å…¥æ˜¯ç°åœ¨çš„è¾“å…¥Xtå’Œä¸Šä¸€ä¸ªæ—¶é—´æ­¥çš„éšè—çŠ¶æ€Ht-1
    é‡ç½®é—¨Rt ï¼šç®—â€œæ–°å†…å®¹â€ä¹‹å‰ï¼Œå…ˆå†³å®šè¦ä¸è¦å‚è€ƒè¿‡å»ã€‚
    æ›´æ–°é—¨Zt ï¼šç®—å®Œâ€œæ–°å†…å®¹â€ä¹‹åï¼Œå†³å®šå†™å¤šå°‘æ–°ã€ç•™å¤šå°‘æ—§ã€‚

è¡¥å……ï¼š
ä»€ä¹ˆå«å€™é€‰çŠ¶æ€ï¼š å«ä¹‰ï¼šæ ¹æ®å½“å‰è¾“å…¥Xtå’Œï¼ˆç»é‡ç½®é—¨rtè¿‡æ»¤åçš„ï¼‰æ—§éšçŠ¶æ€ht-1ç”Ÿæˆçš„æ–°ä¿¡æ¯ææ¡ˆã€‚
'''


import torch
from torch import nn
from LM.d2l import load_data_time_machine, RNNModelScratch, train_ch8, try_gpu, RNNModel

batch_size, num_steps = 32, 35
train_iter, vocab = load_data_time_machine(batch_size, num_steps)

#åˆå§‹åŒ–æ¨¡å‹å‚æ•°
def get_params(vocab_size, num_hiddens, device):
    num_inputs = num_outputs = vocab_size
    # å®šä¹‰ä¸€ä¸ªå‡½æ•°ï¼Œç”¨äºç”Ÿæˆæœä»æ­£æ€åˆ†å¸ƒçš„éšæœºå¼ é‡ï¼Œå¹¶ä¹˜ä»¥0.01è¿›è¡Œç¼©æ”¾
    def normal(shape):
        return torch.randn(size=shape, device=device) * 0.01
    #ç”Ÿæˆä¸‰ç»„æƒé‡å’Œåç½®å¼ é‡ï¼Œç”¨äºä¸åŒçš„é—¨æ§æœºåˆ¶
    def three():
        '''è¿”å›ä¸‰ä¸ªä¸œè¥¿ï¼Œç›´æ¥åˆå§‹åŒ–z-gateçš„wxzï¼Œwhzï¼Œbz'''
        return (normal(
            (num_inputs, num_hiddens)), normal((num_hiddens, num_hiddens)),
                torch.zeros(num_hiddens, device=device))

    # åˆå§‹åŒ–GRUä¸­çš„æƒé‡å’Œåç½®
    # æƒé‡å’Œåç½®ç”¨äºæ§åˆ¶æ›´æ–°é—¨
    W_xz, W_hz, b_z = three()  # ç›¸æ¯”äºRNNï¼ŒGRUå¤šäº†è¿™ä¸¤è¡Œ
    # æƒé‡å’Œåç½®ç”¨äºæ§åˆ¶é‡ç½®é—¨
    W_xr, W_hr, b_r = three()  # GRUå¤šäº†è¿™ä¸¤è¡Œ
    # æƒé‡å’Œåç½®ç”¨äºè®¡ç®—å€™é€‰éšè—çŠ¶æ€
    W_xh, W_hh, b_h = three()
    # éšè—çŠ¶æ€åˆ°è¾“å‡ºçš„æƒé‡
    W_hq = normal((num_hiddens, num_outputs))
    # è¾“å‡ºçš„åç½®
    b_q = torch.zeros(num_outputs, device=device)
    # å‚æ•°åˆ—è¡¨ä¸­å„å‚æ•°é¡ºåº
    params = [W_xz, W_hz, b_z, W_xr, W_hr, b_r, W_xh, W_hh, b_h, W_hq, b_q]
    # éå†å‚æ•°åˆ—è¡¨ä¸­æ‰€æœ‰å‚æ•°
    for param in params:
        # è®¾ç½®å‚æ•°çš„`requires_grad`å±æ€§ä¸ºTrueï¼Œä»¥ä¾¿è¿›è¡Œæ¢¯åº¦è®¡ç®—
        param.requires_grad_(True)
    # è¿”å›å‚æ•°åˆ—è¡¨ä¸­æ‰€æœ‰å‚æ•°
    return params


# å®šä¹‰éšè—çŠ¶æ€çš„åˆå§‹åŒ–å‡½æ•°ï¼Œå› ä¸ºä¸€å¼€å§‹çš„ğŸ‘•æ—¶é—´æ­¥éšè—çŠ¶æ€å¾—ä¸åˆ°
def init_gru_state(batch_size, num_hiddens, device):
    # è¿”å›éšè—çŠ¶æ€åˆå§‹åŒ–ä¸ºå…¨é›¶çš„å…ƒç»„
    return (torch.zeros((batch_size, num_hiddens), device=device),)


#å®šä¹‰GRUé—¨æ§å•å…ƒ
def gru(inputs, state, params):
    #å‚æ•°paramsè§£åŒ…ä¸ºå¤šä¸ªå˜é‡ï¼Œåˆ†åˆ«è¡¨ç¤ºæ¨¡å‹ä¸­çš„æƒé‡å’Œåç½®
    W_xz, W_hz, b_z, W_xr, W_hr, b_r, W_xh, W_hh, b_h, W_hq, b_q = params
    # ä¼ å…¥çš„éšè—çŠ¶æ€ state è§£åŒ…ä¸ºå•ä¸ªå˜é‡ Hã€‚
    H, = state
    # åˆ›å»ºä¸€ä¸ªç©ºåˆ—è¡¨ï¼Œç”¨äºå­˜å‚¨æ¯ä¸ªæ—¶é—´æ­¥çš„è¾“å‡º
    outputs = []
    # éå†è¾“å…¥åºåˆ—ä¸­çš„æ¯ä¸ªæ—¶é—´æ­¥
    for X in inputs:
        #æ›´æ–°é—¨æ§æœºåˆ¶ Z:(B, Hdim) æ›´æ–°é—¨ï¼Œå†³å®šâ€œä¿ç•™æ—§è®°å¿† h_{t-1} çš„æ¯”ä¾‹â€ã€‚W_xz:(I,Hdim), W_hz:(Hdim,Hdim), b_z:(Hdim,)
        Z = torch.sigmoid((X @ W_xz) + (H @ W_hz) + b_z)
        #é‡ç½®é—¨æ§æœºåˆ¶ Rï¼š(B, Hdim) é‡ç½®é—¨ï¼Œå†³å®šâ€œåœ¨ç®—å€™é€‰æ€æ—¶ï¼Œå†å²è¦ä¸è¦å‚ä¸â€
        R = torch.sigmoid((X @ W_xr) + (H @ W_hr) + b_r)
        #è®¡ç®—å€™é€‰éšè—çŠ¶æ€H_tildaï¼ˆï½ï¼‰
        H_tilda = torch.tanh((X @ W_xh) + ((R * H) @ W_hh) + b_h)
        #æ›´æ–°éšè—çŠ¶æ€ H
        H = Z * H + (1 - Z) * H_tilda
        #è®¡ç®—è¾“å‡º Y
        Y = H @ W_hq + b_q
        #å°†è¾“å‡ºæ·»åŠ åˆ°åˆ—è¡¨ä¸­
        outputs.append(Y)
    # å°†æ‰€æœ‰è¾“å‡ºæ‹¼æ¥åœ¨ä¸€èµ·ï¼Œå¹¶è¿”å›æ‹¼æ¥åçš„ç»“æœå’Œæœ€ç»ˆçš„éšè—çŠ¶æ€
    return torch.cat(outputs, dim=0), (H,)


#train
if __name__ == '__main__':
    vocab_size, num_hiddens, device = len(vocab), 256, try_gpu()
    num_epochs, lr = 500, 1
    # #åˆ›å»ºgruå®ä¾‹
    # model = RNNModelScratch(len(vocab), num_hiddens, device, get_params,
    #                            init_gru_state, gru)
    # train_ch8(model, train_iter, vocab, lr, num_epochs, device)



    '''ç®€æ´å®ç°'''
    num_inputs = vocab_size
    gru_layer = nn.GRU(num_inputs, num_hiddens)
    model = RNNModel(gru_layer, len(vocab))
    model = model.to(device)
    train_ch8(model, train_iter, vocab, lr, num_epochs, device)