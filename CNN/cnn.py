'''
1. 从全链接层到卷积，对于全连阶层而言，输入和输出是一个一维向量(N, in_features) -> (N, out_features)
    但是对于卷积而言，输入和输出是多维张量(N, C_in, H, W) -> (N, C_out, H_out, W_out)
    简而言之， 全连接层会把输入打平，丢掉空间结构，直接做全局映射；卷积层保留空间布局，用小窗口扫描输入，参数更少且能捕捉局部特征

2. 平移不变性（translation invariance）： 是cnn的一个重要特征 =》 输入位置发生平移， 输出结果不变
    即一张猫的图片放到左上角和右下角， 网络输出的内容都是cat

3. 平移等变性（translation equivariance）因为卷积核在空间上共享权重， 所以扫描到的特征会随着输入的平移而平移
    cnn要经过pooling和FC layer之后才能具有平移不变性， 否则只有平移等变性
    因为池化pooling做完聚合后会弱化位置信息，FCL的时候剩下的特征都是全局性的所以无论在空间上怎么平移，结果输出都是稳定的 -> 卷积 + 池化 + FC：位置信息逐渐丢失 → 不变性

4. 局部性：locality: cnn中，相邻位置的元素比远处的元素相关性更强
'''